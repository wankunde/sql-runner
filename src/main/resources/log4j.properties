#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Set everything to be logged to the file core/target/unit-tests.log
insight.root.logger=INFO,CA
insight.file.stdout=/tmp/stdout
log4j.rootLogger=${insight.root.logger}

#Console Appender
log4j.appender.CA=org.apache.log4j.ConsoleAppender
log4j.appender.CA.layout=org.apache.log4j.PatternLayout
log4j.appender.CA.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss,SSS} %p %c: %m%n
log4j.appender.CA.Threshold = TRACE
log4j.appender.CA.follow = true

#File Appender
log4j.appender.FA=org.apache.log4j.FileAppender
log4j.appender.FA.append=false
log4j.appender.FA.file=${insight.file.stdout}
log4j.appender.FA.layout=org.apache.log4j.PatternLayout
log4j.appender.FA.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss,SSS} %p %c: %m%n

# Set the logger level of File Appender to WARN
log4j.appender.FA.Threshold = TRACE

# Some packages are noisy for no good reason.
log4j.additivity.parquet.hadoop.ParquetRecordReader=false
log4j.logger.parquet.hadoop.ParquetRecordReader=OFF

log4j.additivity.parquet.hadoop.ParquetOutputCommitter=false
log4j.logger.parquet.hadoop.ParquetOutputCommitter=OFF

log4j.additivity.org.apache.hadoop.hive.serde2.lazy.LazyStruct=false
log4j.logger.org.apache.hadoop.hive.serde2.lazy.LazyStruct=OFF

log4j.additivity.org.apache.hadoop.hive.metastore.RetryingHMSHandler=false
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=OFF

log4j.additivity.hive.ql.metadata.Hive=false
log4j.logger.hive.ql.metadata.Hive=OFF

# Parquet related logging
log4j.logger.parquet.hadoop=WARN
log4j.logger.org.apache.spark.sql.parquet=WARN

log4j.logger.org.spark_project.jetty=ERROR
log4j.logger.org.apache.spark=WARN
log4j.logger.org.apache.spark.deploy.yarn=INFO
log4j.logger.org.apache.hadoop.hive.ql=INFO
log4j.logger.org.apache.hadoop.hive.metastore=WARN
log4j.logger.org.apache.hadoop.hive.ql.log.PerfLogger=WARN
log4j.logger.org.apache.hadoop.mapreduce.lib=INFO
log4j.logger.org.apache.spark.sql=INFO

log4j.logger.BlockManagerMasterEndpoint=ERROR

log4j.logger.org.apache.spark.sql.execution.datasources.FileSourceStrategy=WARN

# to enable RuleExecutor log in Spark2
#log4j.logger.org.apache.spark.sql.hive=TRACE
#log4j.logger.org.apache.spark.sql.hive.client=INFO
#log4j.logger.org.apache.spark.sql.hive.HiveMetastoreCatalog=DEBUG
#log4j.logger.org.apache.spark.sql.execution.FileSourceScanExec=DEBUG

# to enable RuleExecutor log in Spark3, set this configuration in spark_default.xml
#spark.sql.optimizer.planChangeLog.level=INFO
